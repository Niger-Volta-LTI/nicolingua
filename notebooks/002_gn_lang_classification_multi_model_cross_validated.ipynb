{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "from itertools import groupby\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "COLORS = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "ANNOTATIONS_PATH = \"/media/xtrem/data/experiments/nicolingua-0001-language-id/language-id-annotations/metadata.csv\"\n",
    "FEATURE_DIRS = [\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/wav2vec_features-c',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/wav2vec_features-z',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/retrained-wav2vec_features-c',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/retrained-wav2vec_features-z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_specification = {\n",
    "    0: {\n",
    "        'id': 0,\n",
    "        'label': \"maninka\",\n",
    "        'required_tags': set(['ct-speech', 'lng-maninka']),\n",
    "        'forbidden_tags':  set(['lng-susu', 'lng-pular'])\n",
    "    },\n",
    "    1: {\n",
    "        'id': 1,\n",
    "        'label': \"susu\",\n",
    "        'required_tags': set(['ct-speech', 'lng-susu']),\n",
    "        'forbidden_tags':  set(['lng-maninka', 'lng-pular'])\n",
    "    },\n",
    "    2: {\n",
    "        'id': 2,\n",
    "        'label': \"pular\",\n",
    "        'required_tags': set(['ct-speech', 'lng-pular']),\n",
    "        'forbidden_tags':  set(['lng-susu', 'lng-maninka'])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_user_friendly_feature_name(fv_name):\n",
    "    name = fv_name \\\n",
    "        .replace(\"features-\", \"\") \\\n",
    "        .replace(\"wav2vec_\", \"\") \\\n",
    "        .replace(\"average\", \"avg\") \\\n",
    "        .replace(\"timestep\", \"T\") \\\n",
    "        .replace(\"c.\", \"Context\") \\\n",
    "        .replace(\"z.\", \"Latent\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(a_file_path, a_specification):\n",
    "    with open(ANNOTATIONS_PATH) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            tag_set = set([t.strip() for t in row['tags'].split(\";\")])\n",
    "            for label in annotation_specification.keys():\n",
    "                spec = annotation_specification[label]\n",
    "                if spec['required_tags'].issubset(tag_set):\n",
    "                    if spec['forbidden_tags'].isdisjoint(tag_set):\n",
    "                        yield row['file'], label\n",
    "                        break\n",
    "\n",
    "data = list(load_annotations(ANNOTATIONS_PATH, annotation_specification))\n",
    "audio_files, audio_labels = zip(*data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maninka    (0): 114\n",
      "susu       (1): 32\n",
      "pular      (2): 28\n"
     ]
    }
   ],
   "source": [
    "def inspect_label_counts():\n",
    "    for label in annotation_specification:\n",
    "        count = len([l for l in audio_labels if l == label])\n",
    "        print(\"{:10} ({}): {}\".format(\n",
    "            annotation_specification[label]['label'],\n",
    "            label, \n",
    "            count\n",
    "        ))\n",
    "inspect_label_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_class = 28\n",
    "data = list(load_annotations(ANNOTATIONS_PATH, annotation_specification))\n",
    "balanced_data = []\n",
    "for label in annotation_specification:\n",
    "    balanced_data.extend([d for d in data if d[1] == label][:count_per_class])\n",
    "audio_files, audio_labels = zip(*balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maninka    (0): 28\n",
      "susu       (1): 28\n",
      "pular      (2): 28\n"
     ]
    }
   ],
   "source": [
    "inspect_label_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 10 cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = .6\n",
    "FOLD_COUNT = 10\n",
    "\n",
    "n = len(audio_files)\n",
    "n_train = int(np.ceil(n * .6))\n",
    "n_test = n - n_train\n",
    "all_indices = range(n)\n",
    "\n",
    "cv_folds = {}\n",
    "train_count_by_index = {i:0 for i in all_indices}\n",
    "test_count_by_index = {i:0 for i in all_indices}\n",
    "\n",
    "for fold_index in range(FOLD_COUNT):\n",
    "    fold_rsampler = np.random.RandomState(seed=fold_index)\n",
    "    train_index_set = set(fold_rsampler.choice(all_indices, n_train, replace=False))\n",
    "    test_index_set = set(all_indices).difference(train_index_set)\n",
    "        \n",
    "    cv_folds[fold_index] = {\n",
    "        'train_indices': train_index_set,\n",
    "        'test_indices': train_index_set,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(audio_files, features_input_dir):\n",
    "    id_list = []\n",
    "    features_list = []\n",
    "\n",
    "    for audio_file_name in audio_files:\n",
    "        feature_file_name = audio_file_name.replace(\".wav\", \".h5context\")\n",
    "        feature_path = Path(features_input_dir) / feature_file_name\n",
    "        with h5py.File(feature_path, 'r') as f:\n",
    "            features_shape = f['info'][1:].astype(int)\n",
    "            features = np.array(f['features'][:]).reshape(features_shape)\n",
    "            # features = pool_feature_last_seq(features)\n",
    "            features_list.append(features)\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = {}\n",
    "for feature_dir in FEATURE_DIRS:\n",
    "    feature_name = Path(feature_dir).stem\n",
    "    raw_features[feature_name] = load_features(audio_files, feature_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect feature shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_name: c. feature shape: (2998, 512)\n",
      "feature_name: z. feature shape: (2998, 512)\n",
      "feature_name: retrained-c. feature shape: (2998, 512)\n",
      "feature_name: retrained-z. feature shape: (2998, 512)\n"
     ]
    }
   ],
   "source": [
    "for feature_name in raw_features.keys():\n",
    "    print(\"feature_name: {}. feature shape: {}\".format(\n",
    "        to_user_friendly_feature_name(feature_name),\n",
    "        raw_features['wav2vec_features-c'][0].shape\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_timestep_features(raw_features):\n",
    "    return raw_features[-1, :]\n",
    "\n",
    "def extract_neuron_average_features(raw_features):\n",
    "    return np.mean(raw_features, axis=0)\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "feature_extractors = {\n",
    "    'last_timestep': extract_last_timestep_features,\n",
    "    'neuron_average': extract_neuron_average_features,\n",
    "    'raw_features': identity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = {}\n",
    "for feature_name in raw_features.keys():\n",
    "    for feature_extractor_name in feature_extractors.keys():\n",
    "        fv_name = f\"{feature_name}__{feature_extractor_name}\"\n",
    "        feature_vectors[fv_name] = []\n",
    "        for f in raw_features[feature_name]:\n",
    "            feature_vectors[fv_name].append(\n",
    "                feature_extractors[feature_extractor_name](f)\n",
    "            )\n",
    "            \n",
    "        feature_vectors[fv_name] = np.array(feature_vectors[fv_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec_features-c__last_timestep (512,)\n",
      "wav2vec_features-c__neuron_average (512,)\n",
      "wav2vec_features-c__raw_features (2998, 512)\n",
      "wav2vec_features-z__last_timestep (512,)\n",
      "wav2vec_features-z__neuron_average (512,)\n",
      "wav2vec_features-z__raw_features (2998, 512)\n",
      "retrained-wav2vec_features-c__last_timestep (512,)\n",
      "retrained-wav2vec_features-c__neuron_average (512,)\n",
      "retrained-wav2vec_features-c__raw_features (2998, 512)\n",
      "retrained-wav2vec_features-z__last_timestep (512,)\n",
      "retrained-wav2vec_features-z__neuron_average (512,)\n",
      "retrained-wav2vec_features-z__raw_features (2998, 512)\n"
     ]
    }
   ],
   "source": [
    "for fvname in feature_vectors.keys():\n",
    "    print(fvname, feature_vectors[fvname][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_model_summary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangIdConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LangIdConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=512, out_channels=16, kernel_size=3)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=3, kernel_size=3)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(raw_features['wav2vec_features-c']), torch.tensor(audio_labels))\n",
    "loader = DataLoader(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2998, 512])\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1      [10, 16, 2996]          24,592          24,592\n",
      "         Dropout-2      [10, 16, 2996]               0               0\n",
      "       MaxPool1d-3      [10, 16, 1498]               0               0\n",
      "          Conv1d-4      [10, 16, 1496]             784             784\n",
      "         Dropout-5      [10, 16, 1496]               0               0\n",
      "       MaxPool1d-6       [10, 16, 748]               0               0\n",
      "          Conv1d-7       [10, 16, 746]             784             784\n",
      "         Dropout-8       [10, 16, 746]               0               0\n",
      "       MaxPool1d-9       [10, 16, 373]               0               0\n",
      "         Conv1d-10        [10, 3, 371]             147             147\n",
      "      MaxPool1d-11        [10, 3, 185]               0               0\n",
      "=======================================================================\n",
      "Total params: 26,307\n",
      "Trainable params: 26,307\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "1.2651530223734238\n",
      "1.1290022134780884\n",
      "1.1099831847583546\n",
      "1.1060524477678186\n",
      "1.1039341618033016\n",
      "1.1040342625449686\n",
      "1.1029003858566284\n",
      "1.1033631913802202\n",
      "1.107261012582218\n",
      "1.1058895307428696\n",
      "1.1056479846729952\n",
      "1.1035838407628678\n",
      "1.0855524399701286\n",
      "1.1194623147740084\n",
      "1.0871282605563892\n",
      "1.0750802404740278\n",
      "1.089422667727751\n",
      "1.047749053029453\n",
      "1.0943304896354675\n",
      "1.0321001726038315\n",
      "1.0712633588734795\n",
      "1.0186906036208658\n",
      "1.058754044420579\n",
      "1.0008584506371443\n",
      "1.0443605184555054\n",
      "0.9863122421152452\n",
      "1.0274384933359482\n",
      "0.967722987427431\n",
      "1.0063632972100203\n",
      "0.9476052242166856\n",
      "0.993425916222965\n",
      "0.9279553960351383\n",
      "0.9597967372221106\n",
      "0.9179323701297536\n",
      "0.9340834617614746\n",
      "0.9021379842477686\n",
      "0.9071492026833927\n",
      "0.8902153583133922\n",
      "0.8765792636310353\n",
      "0.8673821792883032\n",
      "0.8710709915441626\n",
      "0.8292171534369973\n",
      "0.8516825542730444\n",
      "0.7993199790225309\n",
      "0.8454960234024945\n",
      "0.7597065497847164\n",
      "0.8650275784380296\n",
      "0.7254644474562477\n",
      "0.8319192704032449\n",
      "0.7066036638091592\n",
      "0.7940040651489707\n",
      "0.6941151093034184\n",
      "0.7492601555936477\n",
      "0.6758537239888135\n",
      "0.7361310580197502\n",
      "0.6452633370371426\n",
      "0.7563612846767201\n",
      "0.6070193402907428\n",
      "0.7327444711152244\n",
      "0.608008440803079\n",
      "0.6766931046457851\n",
      "0.5936901043443119\n",
      "0.6311242194736705\n",
      "0.563683990169974\n",
      "0.6310633070328656\n",
      "0.5335254178327673\n",
      "0.5958048201659146\n",
      "0.5061320057686638\n",
      "0.6430442683836993\n",
      "0.5115240303909078\n",
      "0.5128936136470121\n",
      "0.4708435386419296\n",
      "0.5092854157966726\n",
      "0.4542711482328527\n",
      "0.46592828368439393\n",
      "0.4231690668007907\n",
      "0.4559509342207628\n",
      "0.41041085737593036\n",
      "0.39782149826779084\n",
      "0.3772398513906142\n",
      "0.37370683296638374\n",
      "0.3462554014780942\n",
      "0.34756559659453\n",
      "0.3243037843528916\n",
      "0.3038082567646223\n",
      "0.30719178739716024\n",
      "0.2570728477748001\n",
      "0.2720235822831883\n",
      "0.25057780413943176\n",
      "0.2589424116646542\n",
      "0.23518072989057093\n",
      "0.23691515712177053\n",
      "0.21464286656940684\n",
      "0.2124117802390281\n",
      "0.19933105676489718\n",
      "0.19922736221376589\n",
      "0.17632530744680586\n",
      "0.1638330113800133\n",
      "0.16304723710259972\n",
      "0.1466782355461927\n",
      "0.12964812014251947\n",
      "0.12602874828392968\n",
      "0.11539231405100402\n",
      "0.11812200591735103\n",
      "0.10386089991559\n",
      "0.09458904918831061\n",
      "0.09405047414988718\n",
      "0.07672924700412243\n",
      "0.06995949365527314\n",
      "0.05795525834786103\n",
      "0.0535493230118471\n",
      "0.05270753735470969\n",
      "0.05006495679673903\n",
      "0.0464920314569848\n",
      "0.04338122336947195\n",
      "0.04053687322063043\n",
      "0.03433408761424396\n",
      "0.03444392472396002\n",
      "0.02685478823396432\n",
      "0.025439270670176484\n",
      "0.025072553544305265\n",
      "0.02188802320469061\n",
      "0.021141168404617074\n",
      "0.014752934023443446\n",
      "0.019079142365679966\n",
      "0.019026035126230186\n",
      "0.01483527640983298\n",
      "0.011387644760201083\n",
      "0.011155591827392689\n",
      "0.009753307682010071\n",
      "0.013162752582609434\n",
      "0.011933969405671471\n",
      "0.007696870225224891\n",
      "0.008602613035370322\n",
      "0.007016952222329564\n",
      "0.00610040997279986\n",
      "0.006171788272588267\n",
      "0.006632342884960749\n",
      "0.005543074357667458\n",
      "0.006281131277586717\n",
      "0.005787983757994987\n",
      "0.004472433990432525\n",
      "0.006113687182197978\n",
      "0.00481487257146749\n",
      "0.004249106149312437\n",
      "0.003690828011766665\n",
      "0.003234331947811263\n",
      "0.0033563074843293767\n",
      "0.0035876029380554376\n",
      "0.0040173438109751955\n",
      "0.0036543550475685417\n",
      "0.003334878172555524\n",
      "0.002916290865815587\n",
      "0.0023195541260814505\n",
      "0.0021494819849762923\n",
      "0.0022012606611550678\n",
      "0.0025167544130561188\n",
      "0.002053301992204711\n",
      "0.002131377438779643\n",
      "0.0022927407230514184\n",
      "0.002394416841365027\n",
      "0.0017472406883932896\n",
      "0.001812792271213017\n",
      "0.002498949741252813\n",
      "0.0030319929646793753\n",
      "0.00271803795658343\n",
      "0.0013742505027895438\n",
      "0.0015616047329625442\n",
      "0.0013905864201232737\n",
      "0.001165461158426992\n",
      "0.0017108447986281723\n",
      "0.0017992592079013668\n",
      "0.002189906983082491\n",
      "0.0013041995749945806\n",
      "0.001343283455592909\n",
      "0.0012195191546411747\n",
      "0.0013464892695350607\n",
      "0.0012865351046082866\n",
      "0.0010380277069677558\n",
      "0.0011245762147796888\n",
      "0.001076510674358681\n",
      "0.0008805457017682356\n",
      "0.0011373975023482618\n",
      "0.0008747509861731326\n",
      "0.0014344745620880584\n",
      "0.0012238121126917096\n",
      "0.0008132480459286907\n",
      "0.0013249104104568902\n",
      "0.0008517998460721334\n",
      "0.0008208539363883628\n",
      "0.0008842439101499622\n",
      "0.0008749312911437728\n",
      "0.0008280076279548024\n",
      "0.0007996673650589347\n",
      "0.0009898249902428634\n",
      "0.0005775230898132791\n",
      "0.0011971932155360905\n",
      "0.0006785989812134871\n",
      "0.0007711250975583372\n",
      "0.0008751513339709217\n",
      "0.0005675379909328459\n",
      "0.0007038058839123765\n",
      "0.0005607261119781897\n",
      "0.0006165241145080311\n",
      "0.0005866427634507144\n",
      "0.0005380270024889957\n",
      "0.0006828529707062818\n",
      "0.0005826392661594368\n",
      "0.0005338646503386211\n",
      "0.0005776344803641276\n",
      "0.0005450292869147019\n",
      "0.0005261244872706491\n",
      "0.0005795022120497271\n",
      "0.0005289317926272976\n",
      "0.0004364418503909666\n",
      "0.0005899192185819736\n",
      "0.0006600307901060339\n",
      "0.0004034413432236761\n",
      "0.0005724216508657692\n",
      "0.0003946664495582381\n",
      "0.0004731817179805041\n",
      "0.0007100630318745971\n",
      "0.00033711874261023374\n",
      "0.00038624191903877277\n",
      "0.0004906308672883932\n",
      "0.0005068291973068827\n",
      "0.0003640961574680713\n",
      "0.0006094815353876851\n",
      "0.0004948120125417892\n",
      "0.00044494057047974337\n",
      "0.0004894657000905307\n",
      "0.00034084587149236004\n",
      "0.00048046929286476155\n",
      "0.0003981414606374421\n",
      "0.0004773386888914769\n",
      "0.0004848695797163065\n",
      "0.00026307882532872846\n",
      "0.000407197071273699\n",
      "0.0004420360652040793\n",
      "0.0002951941339420848\n",
      "0.00034224655089875504\n",
      "0.0004158537106591479\n",
      "0.00038724328396710916\n",
      "0.0003096813676794387\n",
      "0.00031772161713995636\n",
      "0.0003169600165620068\n",
      "0.0002878534039476054\n",
      "0.0002430481320462765\n",
      "0.00029356021352267654\n",
      "0.00033669210465097206\n",
      "0.00026040524951173106\n",
      "0.0003811175987293074\n",
      "0.00024847109149478083\n",
      "0.0003990587697176927\n",
      "0.0003143156101460216\n",
      "0.00023083693595788858\n",
      "0.00024355533827581573\n",
      "0.0002187195991342271\n",
      "0.00023472971893437824\n",
      "0.00021783983359401806\n",
      "0.00024706918164905375\n"
     ]
    }
   ],
   "source": [
    "model = LangIdConvNet()\n",
    "x = torch.tensor(raw_features['wav2vec_features-c'][:10])\n",
    "print(x.shape)\n",
    "print(summary(LangIdConvNet(), x, show_input=False))\n",
    "\n",
    "    \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(running_loss / len(loader))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-28b029bbbd41>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-28b029bbbd41>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    x_train =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for fold_index in cv_folds:\n",
    "    x_train = \n",
    "    print(fold_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_weights(y):\n",
    "    count_per_class = {k: len(list(g)) for k, g in groupby(sorted(y))}\n",
    "    class_count = len(count_per_class)\n",
    "    weight_per_class = {k: 1/class_count/c for k, c in count_per_class.items()}\n",
    "    return [weight_per_class[yi] for yi in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(audio_labels) // 2\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "\n",
    "for index, fv_name in enumerate(feature_vectors.keys()):\n",
    "    X = feature_vectors[fv_name]\n",
    "    \n",
    "    x_train = X[:train_size]\n",
    "    y_train = audio_labels[:train_size]\n",
    "\n",
    "    x_test = X[train_size:]\n",
    "    y_test = audio_labels[train_size:]\n",
    "\n",
    "    svc = SVC(kernel=\"poly\")\n",
    "    svc.fit(x_train, y_train)\n",
    "\n",
    "    train_acc = svc.score(x_train, y_train, sample_weight=get_sample_weights(y_train))\n",
    "    test_acc = svc.score(x_test, y_test, sample_weight=get_sample_weights(y_test))\n",
    "    print(fv_name, train_acc, test_acc)\n",
    "    \n",
    "    print(f'plt.subplot({2}, {int(np.ceil(len(feature_vectors.keys())/2))}, {index+1})')\n",
    "    plt.subplot(2, int(np.ceil(len(feature_vectors.keys())/2)), index+1)\n",
    "    \n",
    "    projected_x = TSNE(n_components=2).fit_transform(feature_vectors['retrained-wav2vec_features-c__neuron_average'])\n",
    "    plt.scatter(projected_x[:, 0], projected_x[:, 1], c=[COLORS[l] for l in audio_labels])\n",
    "    title = to_user_friendly_feature_name(fv_name)\n",
    "    \n",
    "    title = f\"{title} SVM({train_acc:.02%}, {test_acc:.02%})\"\n",
    "    \n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
