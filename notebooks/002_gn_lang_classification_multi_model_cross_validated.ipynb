{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "from itertools import groupby\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "COLORS = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "ANNOTATIONS_PATH = \"/media/xtrem/data/experiments/nicolingua-0001-language-id/language-id-annotations/metadata.csv\"\n",
    "FEATURE_DIRS = [\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/wav2vec_features-c',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/wav2vec_features-z',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/retrained-wav2vec_features-c',\n",
    "    '/media/xtrem/data/experiments/nicolingua-0001-language-id/retrained-wav2vec_features-z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_specification = {\n",
    "    0: {\n",
    "        'id': 0,\n",
    "        'label': \"maninka\",\n",
    "        'required_tags': set(['ct-speech', 'lng-maninka']),\n",
    "        'forbidden_tags':  set(['lng-susu', 'lng-pular'])\n",
    "    },\n",
    "    1: {\n",
    "        'id': 1,\n",
    "        'label': \"susu\",\n",
    "        'required_tags': set(['ct-speech', 'lng-susu']),\n",
    "        'forbidden_tags':  set(['lng-maninka', 'lng-pular'])\n",
    "    },\n",
    "    2: {\n",
    "        'id': 2,\n",
    "        'label': \"pular\",\n",
    "        'required_tags': set(['ct-speech', 'lng-pular']),\n",
    "        'forbidden_tags':  set(['lng-susu', 'lng-maninka'])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_user_friendly_feature_name(fv_name):\n",
    "    name = fv_name \\\n",
    "        .replace(\"features-\", \"\") \\\n",
    "        .replace(\"wav2vec_\", \"\") \\\n",
    "        .replace(\"average\", \"avg\") \\\n",
    "        .replace(\"timestep\", \"T\") \\\n",
    "        .replace(\"c.\", \"Context\") \\\n",
    "        .replace(\"z.\", \"Latent\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(a_file_path, a_specification):\n",
    "    with open(ANNOTATIONS_PATH) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            tag_set = set([t.strip() for t in row['tags'].split(\";\")])\n",
    "            for label in annotation_specification.keys():\n",
    "                spec = annotation_specification[label]\n",
    "                if spec['required_tags'].issubset(tag_set):\n",
    "                    if spec['forbidden_tags'].isdisjoint(tag_set):\n",
    "                        yield row['file'], label\n",
    "                        break\n",
    "\n",
    "data = list(load_annotations(ANNOTATIONS_PATH, annotation_specification))\n",
    "audio_files, audio_labels = zip(*data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maninka    (0): 114\n",
      "susu       (1): 32\n",
      "pular      (2): 28\n"
     ]
    }
   ],
   "source": [
    "def inspect_label_counts():\n",
    "    for label in annotation_specification:\n",
    "        count = len([l for l in audio_labels if l == label])\n",
    "        print(\"{:10} ({}): {}\".format(\n",
    "            annotation_specification[label]['label'],\n",
    "            label, \n",
    "            count\n",
    "        ))\n",
    "inspect_label_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_class = 28\n",
    "data = list(load_annotations(ANNOTATIONS_PATH, annotation_specification))\n",
    "balanced_data = []\n",
    "for label in annotation_specification:\n",
    "    balanced_data.extend([d for d in data if d[1] == label][:count_per_class])\n",
    "audio_files, audio_labels = zip(*balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maninka    (0): 28\n",
      "susu       (1): 28\n",
      "pular      (2): 28\n"
     ]
    }
   ],
   "source": [
    "inspect_label_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 10 cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = .6\n",
    "FOLD_COUNT = 10\n",
    "\n",
    "n = len(audio_files)\n",
    "n_train = int(np.ceil(n * .6))\n",
    "n_test = n - n_train\n",
    "all_indices = range(n)\n",
    "\n",
    "cv_folds = {}\n",
    "train_count_by_index = {i:0 for i in all_indices}\n",
    "test_count_by_index = {i:0 for i in all_indices}\n",
    "\n",
    "for fold_index in range(FOLD_COUNT):\n",
    "    fold_rsampler = np.random.RandomState(seed=fold_index)\n",
    "    train_index_set = set(fold_rsampler.choice(all_indices, n_train, replace=False))\n",
    "    test_index_set = set(all_indices).difference(train_index_set)\n",
    "        \n",
    "    cv_folds[fold_index] = {\n",
    "        'train_indices': sorted(list(train_index_set)),\n",
    "        'test_indices': sorted(list(train_index_set)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(audio_files, features_input_dir):\n",
    "    id_list = []\n",
    "    features_list = []\n",
    "\n",
    "    for audio_file_name in audio_files:\n",
    "        feature_file_name = audio_file_name.replace(\".wav\", \".h5context\")\n",
    "        feature_path = Path(features_input_dir) / feature_file_name\n",
    "        with h5py.File(feature_path, 'r') as f:\n",
    "            features_shape = f['info'][1:].astype(int)\n",
    "            features = np.array(f['features'][:]).reshape(features_shape)\n",
    "            # features = pool_feature_last_seq(features)\n",
    "            features_list.append(features)\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = {}\n",
    "for feature_dir in FEATURE_DIRS:\n",
    "    feature_name = Path(feature_dir).stem\n",
    "    raw_features[feature_name] = load_features(audio_files, feature_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect feature shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_name: c. feature shape: (2998, 512)\n",
      "feature_name: z. feature shape: (2998, 512)\n",
      "feature_name: retrained-c. feature shape: (2998, 512)\n",
      "feature_name: retrained-z. feature shape: (2998, 512)\n"
     ]
    }
   ],
   "source": [
    "for feature_name in raw_features.keys():\n",
    "    print(\"feature_name: {}. feature shape: {}\".format(\n",
    "        to_user_friendly_feature_name(feature_name),\n",
    "        raw_features['wav2vec_features-c'][0].shape\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_timestep_features(raw_features):\n",
    "    return raw_features[-1, :]\n",
    "\n",
    "def extract_neuron_average_features(raw_features):\n",
    "    return np.mean(raw_features, axis=0)\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "feature_extractors = {\n",
    "    'last_timestep': extract_last_timestep_features,\n",
    "    'neuron_average': extract_neuron_average_features,\n",
    "    'raw_features': identity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = {}\n",
    "for feature_name in raw_features.keys():\n",
    "    for feature_extractor_name in feature_extractors.keys():\n",
    "        fv_name = f\"{feature_name}__{feature_extractor_name}\"\n",
    "        feature_vectors[fv_name] = []\n",
    "        for f in raw_features[feature_name]:\n",
    "            feature_vectors[fv_name].append(\n",
    "                feature_extractors[feature_extractor_name](f)\n",
    "            )\n",
    "            \n",
    "        feature_vectors[fv_name] = np.array(feature_vectors[fv_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec_features-c__last_timestep (512,)\n",
      "wav2vec_features-c__neuron_average (512,)\n",
      "wav2vec_features-c__raw_features (2998, 512)\n",
      "wav2vec_features-z__last_timestep (512,)\n",
      "wav2vec_features-z__neuron_average (512,)\n",
      "wav2vec_features-z__raw_features (2998, 512)\n",
      "retrained-wav2vec_features-c__last_timestep (512,)\n",
      "retrained-wav2vec_features-c__neuron_average (512,)\n",
      "retrained-wav2vec_features-c__raw_features (2998, 512)\n",
      "retrained-wav2vec_features-z__last_timestep (512,)\n",
      "retrained-wav2vec_features-z__neuron_average (512,)\n",
      "retrained-wav2vec_features-z__raw_features (2998, 512)\n"
     ]
    }
   ],
   "source": [
    "for fvname in feature_vectors.keys():\n",
    "    print(fvname, feature_vectors[fvname][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_model_summary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangIdConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LangIdConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=512, out_channels=8, kernel_size=3)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=3)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=3)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(in_channels=8, out_channels=3, kernel_size=3)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_fold(fold_id, batch_size):\n",
    "    train_indices = cv_folds[fold_id]['train_indices']\n",
    "    test_indices = cv_folds[fold_id]['test_indices']\n",
    "\n",
    "    train_x = np.take(raw_features['wav2vec_features-c'], train_indices, axis=0)\n",
    "    train_y = np.take(audio_labels, train_indices, axis=0)\n",
    "\n",
    "    test_x = np.take(raw_features['wav2vec_features-c'], test_indices, axis=0)\n",
    "    test_y = np.take(audio_labels, test_indices, axis=0)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "    \n",
    "def get_loaders_for_fold(fold_id, batch_size):\n",
    "    \n",
    "    train_x, train_y, test_x, test_y = get_data_for_fold(fold_id, batch_size)\n",
    "    \n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_x), \n",
    "        torch.tensor(train_y)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_x), \n",
    "        torch.tensor(test_y)\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_predictions_for_logits(logits):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return torch.argmax(probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1       [10, 8, 2996]          12,296          12,296\n",
      "         Dropout-2       [10, 8, 2996]               0               0\n",
      "       MaxPool1d-3       [10, 8, 1498]               0               0\n",
      "          Conv1d-4       [10, 8, 1496]             200             200\n",
      "         Dropout-5       [10, 8, 1496]               0               0\n",
      "       MaxPool1d-6        [10, 8, 748]               0               0\n",
      "          Conv1d-7        [10, 8, 746]             200             200\n",
      "         Dropout-8        [10, 8, 746]               0               0\n",
      "       MaxPool1d-9        [10, 8, 373]               0               0\n",
      "         Conv1d-10        [10, 3, 371]              75              75\n",
      "      MaxPool1d-11        [10, 3, 185]               0               0\n",
      "=======================================================================\n",
      "Total params: 12,771\n",
      "Trainable params: 12,771\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "Epoch: 0. Train Loss: 1.126. Test Loss: 1.105. Train Acc: 0.3529. Test Acc:0.3529\n",
      "Epoch: 1. Train Loss: 1.103. Test Loss: 1.102. Train Acc: 0.3529. Test Acc:0.3529\n",
      "Epoch: 2. Train Loss: 1.098. Test Loss: 1.099. Train Acc: 0.3529. Test Acc:0.3529\n",
      "Epoch: 3. Train Loss: 1.095. Test Loss: 1.096. Train Acc: 0.3529. Test Acc:0.3529\n",
      "Epoch: 4. Train Loss: 1.092. Test Loss: 1.093. Train Acc: 0.3529. Test Acc:0.3529\n",
      "Epoch: 5. Train Loss: 1.091. Test Loss: 1.091. Train Acc: 0.451. Test Acc:0.4314\n",
      "Epoch: 6. Train Loss: 1.088. Test Loss: 1.088. Train Acc: 0.3725. Test Acc:0.3137\n",
      "Epoch: 7. Train Loss: 1.085. Test Loss: 1.086. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 8. Train Loss: 1.082. Test Loss: 1.083. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 9. Train Loss: 1.079. Test Loss: 1.08. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 10. Train Loss: 1.077. Test Loss: 1.078. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 11. Train Loss: 1.073. Test Loss: 1.075. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 12. Train Loss: 1.071. Test Loss: 1.072. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 13. Train Loss: 1.069. Test Loss: 1.069. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 14. Train Loss: 1.066. Test Loss: 1.066. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 15. Train Loss: 1.065. Test Loss: 1.063. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 16. Train Loss: 1.061. Test Loss: 1.059. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 17. Train Loss: 1.058. Test Loss: 1.055. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 18. Train Loss: 1.055. Test Loss: 1.049. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 19. Train Loss: 1.048. Test Loss: 1.043. Train Acc: 0.3137. Test Acc:0.3137\n",
      "Epoch: 20. Train Loss: 1.045. Test Loss: 1.036. Train Acc: 0.3137. Test Acc:0.3529\n",
      "Epoch: 21. Train Loss: 1.033. Test Loss: 1.027. Train Acc: 0.3333. Test Acc:0.3725\n",
      "Epoch: 22. Train Loss: 1.024. Test Loss: 1.017. Train Acc: 0.3529. Test Acc:0.3725\n",
      "Epoch: 23. Train Loss: 1.011. Test Loss: 1.005. Train Acc: 0.3725. Test Acc:0.3725\n",
      "Epoch: 24. Train Loss: 0.9989. Test Loss: 0.9923. Train Acc: 0.3725. Test Acc:0.4118\n",
      "Epoch: 25. Train Loss: 0.9876. Test Loss: 0.9787. Train Acc: 0.3922. Test Acc:0.451\n",
      "Epoch: 26. Train Loss: 0.973. Test Loss: 0.9643. Train Acc: 0.4118. Test Acc:0.4902\n",
      "Epoch: 27. Train Loss: 0.9546. Test Loss: 0.9493. Train Acc: 0.4902. Test Acc:0.5098\n",
      "Epoch: 28. Train Loss: 0.9418. Test Loss: 0.9343. Train Acc: 0.4902. Test Acc:0.5098\n",
      "Epoch: 29. Train Loss: 0.9245. Test Loss: 0.9192. Train Acc: 0.4706. Test Acc:0.5098\n",
      "Epoch: 30. Train Loss: 0.911. Test Loss: 0.9042. Train Acc: 0.4902. Test Acc:0.5294\n",
      "Epoch: 31. Train Loss: 0.8904. Test Loss: 0.889. Train Acc: 0.4902. Test Acc:0.549\n",
      "Epoch: 32. Train Loss: 0.8789. Test Loss: 0.8752. Train Acc: 0.4902. Test Acc:0.5294\n",
      "Epoch: 33. Train Loss: 0.8677. Test Loss: 0.8623. Train Acc: 0.4902. Test Acc:0.5294\n",
      "Epoch: 34. Train Loss: 0.8493. Test Loss: 0.849. Train Acc: 0.4902. Test Acc:0.5294\n",
      "Epoch: 35. Train Loss: 0.8418. Test Loss: 0.8372. Train Acc: 0.5098. Test Acc:0.549\n",
      "Epoch: 36. Train Loss: 0.8302. Test Loss: 0.8266. Train Acc: 0.549. Test Acc:0.549\n",
      "Epoch: 37. Train Loss: 0.8189. Test Loss: 0.8161. Train Acc: 0.549. Test Acc:0.5686\n",
      "Epoch: 38. Train Loss: 0.8052. Test Loss: 0.8068. Train Acc: 0.5686. Test Acc:0.5882\n",
      "Epoch: 39. Train Loss: 0.7989. Test Loss: 0.7982. Train Acc: 0.5882. Test Acc:0.6078\n",
      "Epoch: 40. Train Loss: 0.7916. Test Loss: 0.7897. Train Acc: 0.5882. Test Acc:0.6078\n",
      "Epoch: 41. Train Loss: 0.7812. Test Loss: 0.7818. Train Acc: 0.5686. Test Acc:0.5686\n",
      "Epoch: 42. Train Loss: 0.7783. Test Loss: 0.7752. Train Acc: 0.549. Test Acc:0.5882\n",
      "Epoch: 43. Train Loss: 0.7693. Test Loss: 0.7684. Train Acc: 0.5098. Test Acc:0.6078\n",
      "Epoch: 44. Train Loss: 0.7662. Test Loss: 0.7622. Train Acc: 0.549. Test Acc:0.5686\n",
      "Epoch: 45. Train Loss: 0.7557. Test Loss: 0.7561. Train Acc: 0.5294. Test Acc:0.6078\n",
      "Epoch: 46. Train Loss: 0.7537. Test Loss: 0.7513. Train Acc: 0.549. Test Acc:0.6078\n",
      "Epoch: 47. Train Loss: 0.7465. Test Loss: 0.746. Train Acc: 0.5686. Test Acc:0.6275\n",
      "Epoch: 48. Train Loss: 0.7407. Test Loss: 0.7406. Train Acc: 0.549. Test Acc:0.6471\n",
      "Epoch: 49. Train Loss: 0.7383. Test Loss: 0.7359. Train Acc: 0.5882. Test Acc:0.6471\n",
      "Epoch: 50. Train Loss: 0.7354. Test Loss: 0.7315. Train Acc: 0.5098. Test Acc:0.6471\n",
      "Epoch: 51. Train Loss: 0.7258. Test Loss: 0.7271. Train Acc: 0.549. Test Acc:0.6471\n",
      "Epoch: 52. Train Loss: 0.7202. Test Loss: 0.7228. Train Acc: 0.549. Test Acc:0.6471\n",
      "Epoch: 53. Train Loss: 0.7241. Test Loss: 0.7192. Train Acc: 0.5294. Test Acc:0.6667\n",
      "Epoch: 54. Train Loss: 0.7113. Test Loss: 0.7145. Train Acc: 0.5686. Test Acc:0.6667\n",
      "Epoch: 55. Train Loss: 0.7101. Test Loss: 0.7111. Train Acc: 0.6275. Test Acc:0.6667\n",
      "Epoch: 56. Train Loss: 0.7038. Test Loss: 0.7073. Train Acc: 0.6275. Test Acc:0.6667\n",
      "Epoch: 57. Train Loss: 0.7009. Test Loss: 0.7031. Train Acc: 0.5882. Test Acc:0.6667\n",
      "Epoch: 58. Train Loss: 0.6976. Test Loss: 0.6998. Train Acc: 0.6078. Test Acc:0.6667\n",
      "Epoch: 59. Train Loss: 0.6973. Test Loss: 0.697. Train Acc: 0.6275. Test Acc:0.6667\n",
      "Epoch: 60. Train Loss: 0.6908. Test Loss: 0.6925. Train Acc: 0.6078. Test Acc:0.6667\n",
      "Epoch: 61. Train Loss: 0.6859. Test Loss: 0.689. Train Acc: 0.5686. Test Acc:0.6863\n",
      "Epoch: 62. Train Loss: 0.6878. Test Loss: 0.6862. Train Acc: 0.6275. Test Acc:0.6667\n",
      "Epoch: 63. Train Loss: 0.6807. Test Loss: 0.6827. Train Acc: 0.6078. Test Acc:0.6863\n",
      "Epoch: 64. Train Loss: 0.6737. Test Loss: 0.6797. Train Acc: 0.5686. Test Acc:0.6667\n",
      "Epoch: 65. Train Loss: 0.6739. Test Loss: 0.676. Train Acc: 0.6275. Test Acc:0.6863\n",
      "Epoch: 66. Train Loss: 0.6697. Test Loss: 0.6727. Train Acc: 0.6078. Test Acc:0.6667\n",
      "Epoch: 67. Train Loss: 0.6712. Test Loss: 0.6701. Train Acc: 0.6275. Test Acc:0.6667\n",
      "Epoch: 68. Train Loss: 0.6565. Test Loss: 0.6661. Train Acc: 0.6667. Test Acc:0.6863\n",
      "Epoch: 69. Train Loss: 0.6551. Test Loss: 0.6628. Train Acc: 0.6471. Test Acc:0.6863\n",
      "Epoch: 70. Train Loss: 0.6559. Test Loss: 0.66. Train Acc: 0.6471. Test Acc:0.6863\n",
      "Epoch: 71. Train Loss: 0.6503. Test Loss: 0.6566. Train Acc: 0.6863. Test Acc:0.6863\n",
      "Epoch: 72. Train Loss: 0.6467. Test Loss: 0.6533. Train Acc: 0.6667. Test Acc:0.6863\n",
      "Epoch: 73. Train Loss: 0.6488. Test Loss: 0.6502. Train Acc: 0.6863. Test Acc:0.6863\n",
      "Epoch: 74. Train Loss: 0.6363. Test Loss: 0.6466. Train Acc: 0.7059. Test Acc:0.6863\n",
      "Epoch: 75. Train Loss: 0.6392. Test Loss: 0.6434. Train Acc: 0.6863. Test Acc:0.6863\n",
      "Epoch: 76. Train Loss: 0.6319. Test Loss: 0.6395. Train Acc: 0.6863. Test Acc:0.6863\n",
      "Epoch: 77. Train Loss: 0.6304. Test Loss: 0.6373. Train Acc: 0.7059. Test Acc:0.6863\n",
      "Epoch: 78. Train Loss: 0.6227. Test Loss: 0.6332. Train Acc: 0.6667. Test Acc:0.6863\n",
      "Epoch: 79. Train Loss: 0.6166. Test Loss: 0.6295. Train Acc: 0.7059. Test Acc:0.6863\n",
      "Epoch: 80. Train Loss: 0.6151. Test Loss: 0.6266. Train Acc: 0.7059. Test Acc:0.6863\n",
      "Epoch: 81. Train Loss: 0.6107. Test Loss: 0.6226. Train Acc: 0.7451. Test Acc:0.7255\n",
      "Epoch: 82. Train Loss: 0.61. Test Loss: 0.6194. Train Acc: 0.7255. Test Acc:0.7255\n",
      "Epoch: 83. Train Loss: 0.6009. Test Loss: 0.6159. Train Acc: 0.6863. Test Acc:0.7255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84. Train Loss: 0.6001. Test Loss: 0.6128. Train Acc: 0.7059. Test Acc:0.7451\n",
      "Epoch: 85. Train Loss: 0.5906. Test Loss: 0.6087. Train Acc: 0.7647. Test Acc:0.7451\n",
      "Epoch: 86. Train Loss: 0.5868. Test Loss: 0.6039. Train Acc: 0.7647. Test Acc:0.7647\n",
      "Epoch: 87. Train Loss: 0.5849. Test Loss: 0.6011. Train Acc: 0.7647. Test Acc:0.7451\n",
      "Epoch: 88. Train Loss: 0.5846. Test Loss: 0.5978. Train Acc: 0.7647. Test Acc:0.7647\n",
      "Epoch: 89. Train Loss: 0.5678. Test Loss: 0.592. Train Acc: 0.7451. Test Acc:0.7647\n",
      "Epoch: 90. Train Loss: 0.5721. Test Loss: 0.5897. Train Acc: 0.7843. Test Acc:0.7647\n",
      "Epoch: 91. Train Loss: 0.5653. Test Loss: 0.5839. Train Acc: 0.8039. Test Acc:0.7451\n",
      "Epoch: 92. Train Loss: 0.5619. Test Loss: 0.5807. Train Acc: 0.7647. Test Acc:0.7451\n",
      "Epoch: 93. Train Loss: 0.5558. Test Loss: 0.5767. Train Acc: 0.8039. Test Acc:0.7451\n",
      "Epoch: 94. Train Loss: 0.5504. Test Loss: 0.5714. Train Acc: 0.7451. Test Acc:0.7451\n",
      "Epoch: 95. Train Loss: 0.5541. Test Loss: 0.5684. Train Acc: 0.7647. Test Acc:0.7451\n",
      "Epoch: 96. Train Loss: 0.5401. Test Loss: 0.5628. Train Acc: 0.7647. Test Acc:0.7647\n",
      "Epoch: 97. Train Loss: 0.5359. Test Loss: 0.5577. Train Acc: 0.7647. Test Acc:0.7647\n",
      "Epoch: 98. Train Loss: 0.524. Test Loss: 0.5536. Train Acc: 0.8235. Test Acc:0.7843\n",
      "Epoch: 99. Train Loss: 0.5257. Test Loss: 0.5492. Train Acc: 0.7843. Test Acc:0.7843\n",
      "Epoch: 100. Train Loss: 0.5189. Test Loss: 0.5431. Train Acc: 0.8039. Test Acc:0.8039\n",
      "Epoch: 101. Train Loss: 0.5147. Test Loss: 0.5387. Train Acc: 0.7843. Test Acc:0.8039\n",
      "Epoch: 102. Train Loss: 0.5072. Test Loss: 0.5348. Train Acc: 0.7843. Test Acc:0.8039\n",
      "Epoch: 103. Train Loss: 0.5016. Test Loss: 0.5278. Train Acc: 0.7843. Test Acc:0.8235\n",
      "Epoch: 104. Train Loss: 0.4974. Test Loss: 0.5232. Train Acc: 0.7843. Test Acc:0.8039\n",
      "Epoch: 105. Train Loss: 0.4895. Test Loss: 0.5186. Train Acc: 0.8039. Test Acc:0.8039\n",
      "Epoch: 106. Train Loss: 0.4765. Test Loss: 0.5115. Train Acc: 0.8431. Test Acc:0.8235\n",
      "Epoch: 107. Train Loss: 0.4788. Test Loss: 0.508. Train Acc: 0.8039. Test Acc:0.8235\n",
      "Epoch: 108. Train Loss: 0.4697. Test Loss: 0.5006. Train Acc: 0.8235. Test Acc:0.8235\n",
      "Epoch: 109. Train Loss: 0.4595. Test Loss: 0.4953. Train Acc: 0.8235. Test Acc:0.8235\n",
      "Epoch: 110. Train Loss: 0.4574. Test Loss: 0.4914. Train Acc: 0.8627. Test Acc:0.8431\n",
      "Epoch: 111. Train Loss: 0.4483. Test Loss: 0.4826. Train Acc: 0.8235. Test Acc:0.8235\n",
      "Epoch: 112. Train Loss: 0.4382. Test Loss: 0.4792. Train Acc: 0.8235. Test Acc:0.8431\n",
      "Epoch: 113. Train Loss: 0.4258. Test Loss: 0.4719. Train Acc: 0.8431. Test Acc:0.8235\n",
      "Epoch: 114. Train Loss: 0.4285. Test Loss: 0.4656. Train Acc: 0.8235. Test Acc:0.8431\n",
      "Epoch: 115. Train Loss: 0.4208. Test Loss: 0.4622. Train Acc: 0.8235. Test Acc:0.8627\n",
      "Epoch: 116. Train Loss: 0.4076. Test Loss: 0.4532. Train Acc: 0.8235. Test Acc:0.8627\n",
      "Epoch: 117. Train Loss: 0.4086. Test Loss: 0.4517. Train Acc: 0.8431. Test Acc:0.8824\n",
      "Epoch: 118. Train Loss: 0.3885. Test Loss: 0.4411. Train Acc: 0.8627. Test Acc:0.8627\n",
      "Epoch: 119. Train Loss: 0.3913. Test Loss: 0.4387. Train Acc: 0.8431. Test Acc:0.902\n",
      "Epoch: 120. Train Loss: 0.3856. Test Loss: 0.4303. Train Acc: 0.8235. Test Acc:0.8824\n",
      "Epoch: 121. Train Loss: 0.3766. Test Loss: 0.4224. Train Acc: 0.8627. Test Acc:0.9216\n",
      "Epoch: 122. Train Loss: 0.3672. Test Loss: 0.4191. Train Acc: 0.8431. Test Acc:0.9216\n",
      "Epoch: 123. Train Loss: 0.3635. Test Loss: 0.4104. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 124. Train Loss: 0.3623. Test Loss: 0.4092. Train Acc: 0.8431. Test Acc:0.9412\n",
      "Epoch: 125. Train Loss: 0.3464. Test Loss: 0.399. Train Acc: 0.8824. Test Acc:0.9412\n",
      "Epoch: 126. Train Loss: 0.3441. Test Loss: 0.396. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 127. Train Loss: 0.3381. Test Loss: 0.3886. Train Acc: 0.8431. Test Acc:0.9412\n",
      "Epoch: 128. Train Loss: 0.3346. Test Loss: 0.381. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 129. Train Loss: 0.3235. Test Loss: 0.3772. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 130. Train Loss: 0.3148. Test Loss: 0.3706. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 131. Train Loss: 0.3081. Test Loss: 0.3625. Train Acc: 0.8824. Test Acc:0.9412\n",
      "Epoch: 132. Train Loss: 0.3054. Test Loss: 0.3594. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 133. Train Loss: 0.2955. Test Loss: 0.3508. Train Acc: 0.8824. Test Acc:0.9412\n",
      "Epoch: 134. Train Loss: 0.294. Test Loss: 0.3485. Train Acc: 0.8627. Test Acc:0.9412\n",
      "Epoch: 135. Train Loss: 0.2804. Test Loss: 0.3417. Train Acc: 0.902. Test Acc:0.9412\n",
      "Epoch: 136. Train Loss: 0.2672. Test Loss: 0.3353. Train Acc: 0.902. Test Acc:0.9412\n",
      "Epoch: 137. Train Loss: 0.2713. Test Loss: 0.332. Train Acc: 0.902. Test Acc:0.9804\n",
      "Epoch: 138. Train Loss: 0.2655. Test Loss: 0.3236. Train Acc: 0.902. Test Acc:0.9608\n",
      "Epoch: 139. Train Loss: 0.2597. Test Loss: 0.3227. Train Acc: 0.9216. Test Acc:0.9804\n",
      "Epoch: 140. Train Loss: 0.2497. Test Loss: 0.3108. Train Acc: 0.9216. Test Acc:0.9608\n",
      "Epoch: 141. Train Loss: 0.2525. Test Loss: 0.3107. Train Acc: 0.9216. Test Acc:0.9608\n",
      "Epoch: 142. Train Loss: 0.2414. Test Loss: 0.3003. Train Acc: 0.9216. Test Acc:0.9608\n",
      "Epoch: 143. Train Loss: 0.2404. Test Loss: 0.3048. Train Acc: 0.9216. Test Acc:0.9804\n",
      "Epoch: 144. Train Loss: 0.2225. Test Loss: 0.288. Train Acc: 0.9216. Test Acc:0.9608\n",
      "Epoch: 145. Train Loss: 0.2282. Test Loss: 0.2932. Train Acc: 0.9412. Test Acc:0.9804\n",
      "Epoch: 146. Train Loss: 0.2147. Test Loss: 0.2794. Train Acc: 0.9216. Test Acc:0.9608\n",
      "Epoch: 147. Train Loss: 0.2139. Test Loss: 0.2779. Train Acc: 0.9412. Test Acc:0.9804\n",
      "Epoch: 148. Train Loss: 0.2002. Test Loss: 0.2738. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 149. Train Loss: 0.2086. Test Loss: 0.265. Train Acc: 0.9412. Test Acc:0.9608\n",
      "Epoch: 150. Train Loss: 0.1987. Test Loss: 0.2625. Train Acc: 0.9412. Test Acc:0.9804\n",
      "Epoch: 151. Train Loss: 0.1874. Test Loss: 0.2584. Train Acc: 0.9608. Test Acc:0.9804\n",
      "Epoch: 152. Train Loss: 0.1895. Test Loss: 0.2516. Train Acc: 0.9412. Test Acc:1.0\n",
      "Epoch: 153. Train Loss: 0.175. Test Loss: 0.2512. Train Acc: 0.9608. Test Acc:0.9804\n",
      "Epoch: 154. Train Loss: 0.1733. Test Loss: 0.2426. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 155. Train Loss: 0.167. Test Loss: 0.2372. Train Acc: 0.9608. Test Acc:1.0\n",
      "Epoch: 156. Train Loss: 0.1628. Test Loss: 0.2366. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 157. Train Loss: 0.165. Test Loss: 0.2249. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 158. Train Loss: 0.1595. Test Loss: 0.239. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 159. Train Loss: 0.1469. Test Loss: 0.2154. Train Acc: 0.9608. Test Acc:0.9804\n",
      "Epoch: 160. Train Loss: 0.1562. Test Loss: 0.2249. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 161. Train Loss: 0.1457. Test Loss: 0.2077. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 162. Train Loss: 0.1459. Test Loss: 0.2154. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 163. Train Loss: 0.1372. Test Loss: 0.1996. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 164. Train Loss: 0.1304. Test Loss: 0.2081. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 165. Train Loss: 0.1237. Test Loss: 0.1913. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 166. Train Loss: 0.1223. Test Loss: 0.2011. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 167. Train Loss: 0.1159. Test Loss: 0.1826. Train Acc: 0.9804. Test Acc:0.9804\n",
      "Epoch: 168. Train Loss: 0.1161. Test Loss: 0.1901. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 169. Train Loss: 0.1063. Test Loss: 0.1806. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 170. Train Loss: 0.1102. Test Loss: 0.1816. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 171. Train Loss: 0.108. Test Loss: 0.1694. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 172. Train Loss: 0.1029. Test Loss: 0.1774. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 173. Train Loss: 0.0961. Test Loss: 0.1625. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 174. Train Loss: 0.09593. Test Loss: 0.1706. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 175. Train Loss: 0.08804. Test Loss: 0.1569. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 176. Train Loss: 0.09343. Test Loss: 0.1647. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 177. Train Loss: 0.09061. Test Loss: 0.15. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 178. Train Loss: 0.08264. Test Loss: 0.1563. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 179. Train Loss: 0.07901. Test Loss: 0.1437. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 180. Train Loss: 0.07709. Test Loss: 0.1512. Train Acc: 0.9804. Test Acc:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181. Train Loss: 0.07773. Test Loss: 0.1373. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 182. Train Loss: 0.07404. Test Loss: 0.1473. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 183. Train Loss: 0.07033. Test Loss: 0.1324. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 184. Train Loss: 0.06789. Test Loss: 0.1377. Train Acc: 0.9804. Test Acc:1.0\n",
      "Epoch: 185. Train Loss: 0.06544. Test Loss: 0.1286. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 186. Train Loss: 0.06628. Test Loss: 0.132. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 187. Train Loss: 0.05913. Test Loss: 0.1234. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 188. Train Loss: 0.06038. Test Loss: 0.1281. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 189. Train Loss: 0.055. Test Loss: 0.1171. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 190. Train Loss: 0.05943. Test Loss: 0.1225. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 191. Train Loss: 0.0521. Test Loss: 0.1164. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 192. Train Loss: 0.05181. Test Loss: 0.1152. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 193. Train Loss: 0.05135. Test Loss: 0.1107. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 194. Train Loss: 0.04835. Test Loss: 0.1112. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 195. Train Loss: 0.04464. Test Loss: 0.1075. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 196. Train Loss: 0.04544. Test Loss: 0.1047. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 197. Train Loss: 0.04253. Test Loss: 0.1071. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 198. Train Loss: 0.0427. Test Loss: 0.1002. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 199. Train Loss: 0.03992. Test Loss: 0.1011. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 200. Train Loss: 0.04106. Test Loss: 0.09873. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 201. Train Loss: 0.03955. Test Loss: 0.09708. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 202. Train Loss: 0.0367. Test Loss: 0.09508. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 203. Train Loss: 0.03662. Test Loss: 0.0953. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 204. Train Loss: 0.03691. Test Loss: 0.09029. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 205. Train Loss: 0.03501. Test Loss: 0.09192. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 206. Train Loss: 0.03149. Test Loss: 0.08643. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 207. Train Loss: 0.0327. Test Loss: 0.0857. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 208. Train Loss: 0.02967. Test Loss: 0.0857. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 209. Train Loss: 0.0325. Test Loss: 0.08423. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 210. Train Loss: 0.02963. Test Loss: 0.08342. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 211. Train Loss: 0.03084. Test Loss: 0.08015. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 212. Train Loss: 0.02791. Test Loss: 0.08005. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 213. Train Loss: 0.02577. Test Loss: 0.08192. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 214. Train Loss: 0.02704. Test Loss: 0.07573. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 215. Train Loss: 0.02665. Test Loss: 0.07707. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 216. Train Loss: 0.0236. Test Loss: 0.07824. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 217. Train Loss: 0.0253. Test Loss: 0.07156. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 218. Train Loss: 0.02407. Test Loss: 0.07668. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 219. Train Loss: 0.02673. Test Loss: 0.07095. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 220. Train Loss: 0.02062. Test Loss: 0.06981. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 221. Train Loss: 0.02168. Test Loss: 0.07437. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 222. Train Loss: 0.02145. Test Loss: 0.06723. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 223. Train Loss: 0.02132. Test Loss: 0.06719. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 224. Train Loss: 0.0182. Test Loss: 0.06968. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 225. Train Loss: 0.01883. Test Loss: 0.06349. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 226. Train Loss: 0.02169. Test Loss: 0.07055. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 227. Train Loss: 0.01826. Test Loss: 0.0623. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 228. Train Loss: 0.01964. Test Loss: 0.06411. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 229. Train Loss: 0.01712. Test Loss: 0.0616. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 230. Train Loss: 0.01832. Test Loss: 0.0614. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 231. Train Loss: 0.01729. Test Loss: 0.06001. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 232. Train Loss: 0.01913. Test Loss: 0.05934. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 233. Train Loss: 0.01487. Test Loss: 0.059. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 234. Train Loss: 0.01633. Test Loss: 0.05699. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 235. Train Loss: 0.01495. Test Loss: 0.05952. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 236. Train Loss: 0.01469. Test Loss: 0.05662. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 237. Train Loss: 0.01426. Test Loss: 0.05617. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 238. Train Loss: 0.01413. Test Loss: 0.05519. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 239. Train Loss: 0.01335. Test Loss: 0.05407. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 240. Train Loss: 0.01258. Test Loss: 0.05315. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 241. Train Loss: 0.01181. Test Loss: 0.05301. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 242. Train Loss: 0.0121. Test Loss: 0.0525. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 243. Train Loss: 0.01303. Test Loss: 0.05188. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 244. Train Loss: 0.01208. Test Loss: 0.05273. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 245. Train Loss: 0.01211. Test Loss: 0.05045. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 246. Train Loss: 0.01201. Test Loss: 0.04963. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 247. Train Loss: 0.01001. Test Loss: 0.05027. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 248. Train Loss: 0.01185. Test Loss: 0.04878. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 249. Train Loss: 0.01099. Test Loss: 0.04866. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 250. Train Loss: 0.01067. Test Loss: 0.04859. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 251. Train Loss: 0.009887. Test Loss: 0.04676. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 252. Train Loss: 0.01066. Test Loss: 0.04776. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 253. Train Loss: 0.009893. Test Loss: 0.04796. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 254. Train Loss: 0.01131. Test Loss: 0.04519. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 255. Train Loss: 0.0116. Test Loss: 0.04573. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 256. Train Loss: 0.009534. Test Loss: 0.04502. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 257. Train Loss: 0.009378. Test Loss: 0.04509. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 258. Train Loss: 0.009952. Test Loss: 0.04456. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 259. Train Loss: 0.008487. Test Loss: 0.04381. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 260. Train Loss: 0.009296. Test Loss: 0.04404. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 261. Train Loss: 0.01046. Test Loss: 0.04277. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 262. Train Loss: 0.007736. Test Loss: 0.04259. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 263. Train Loss: 0.008555. Test Loss: 0.04166. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 264. Train Loss: 0.008343. Test Loss: 0.0409. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 265. Train Loss: 0.009278. Test Loss: 0.04264. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 266. Train Loss: 0.007979. Test Loss: 0.04301. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 267. Train Loss: 0.008713. Test Loss: 0.0424. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 268. Train Loss: 0.00788. Test Loss: 0.03969. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 269. Train Loss: 0.008318. Test Loss: 0.03914. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 270. Train Loss: 0.008112. Test Loss: 0.04022. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 271. Train Loss: 0.007228. Test Loss: 0.0393. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 272. Train Loss: 0.007679. Test Loss: 0.03766. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 273. Train Loss: 0.007883. Test Loss: 0.03928. Train Acc: 1.0. Test Acc:1.0\n",
      "Epoch: 274. Train Loss: 0.008393. Test Loss: 0.03791. Train Acc: 1.0. Test Acc:1.0\n"
     ]
    }
   ],
   "source": [
    "model = LangIdConvNet()\n",
    "\n",
    "train_loader, test_loader = get_loaders_for_fold(0, 10)\n",
    "\n",
    "print(summary(LangIdConvNet(), torch.zeros((10, 2998, 512)), show_input=False))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    pred_train_classes = []\n",
    "    true_train_classes = []\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        pred_train_classes.extend(\n",
    "            get_predictions_for_logits(outputs)\n",
    "        )\n",
    "        true_train_classes.extend(y)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    train_acc = sklearn.metrics.accuracy_score(true_train_classes, pred_train_classes)\n",
    "    \n",
    "    \n",
    "    pred_test_classes = []\n",
    "    true_test_classes = []\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        outputs = model(x)\n",
    "        \n",
    "        pred_test_classes.extend(\n",
    "            get_predictions_for_logits(outputs)\n",
    "        )\n",
    "        \n",
    "        true_test_classes.extend(y)\n",
    "        \n",
    "        loss = criterion(outputs, y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = sklearn.metrics.accuracy_score(true_test_classes, pred_test_classes)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch: {epoch}. Train Loss: {train_loss:0.4}. Test Loss: {test_loss:0.4}. Train Acc: {train_acc:0.4}. Test Acc:{test_acc:0.4}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_index in cv_folds:\n",
    "    x_train = \n",
    "    print(fold_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_weights(y):\n",
    "    count_per_class = {k: len(list(g)) for k, g in groupby(sorted(y))}\n",
    "    class_count = len(count_per_class)\n",
    "    weight_per_class = {k: 1/class_count/c for k, c in count_per_class.items()}\n",
    "    return [weight_per_class[yi] for yi in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(audio_labels) // 2\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "\n",
    "for index, fv_name in enumerate(feature_vectors.keys()):\n",
    "    X = feature_vectors[fv_name]\n",
    "    \n",
    "    x_train = X[:train_size]\n",
    "    y_train = audio_labels[:train_size]\n",
    "\n",
    "    x_test = X[train_size:]\n",
    "    y_test = audio_labels[train_size:]\n",
    "\n",
    "    svc = SVC(kernel=\"poly\")\n",
    "    svc.fit(x_train, y_train)\n",
    "\n",
    "    train_acc = svc.score(x_train, y_train, sample_weight=get_sample_weights(y_train))\n",
    "    test_acc = svc.score(x_test, y_test, sample_weight=get_sample_weights(y_test))\n",
    "    print(fv_name, train_acc, test_acc)\n",
    "    \n",
    "    print(f'plt.subplot({2}, {int(np.ceil(len(feature_vectors.keys())/2))}, {index+1})')\n",
    "    plt.subplot(2, int(np.ceil(len(feature_vectors.keys())/2)), index+1)\n",
    "    \n",
    "    projected_x = TSNE(n_components=2).fit_transform(feature_vectors['retrained-wav2vec_features-c__neuron_average'])\n",
    "    plt.scatter(projected_x[:, 0], projected_x[:, 1], c=[COLORS[l] for l in audio_labels])\n",
    "    title = to_user_friendly_feature_name(fv_name)\n",
    "    \n",
    "    title = f\"{title} SVM({train_acc:.02%}, {test_acc:.02%})\"\n",
    "    \n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
